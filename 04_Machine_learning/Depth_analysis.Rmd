---
title: "Maching_Learning_viz"
author: "Maria Popescu"
date: "2025-05-30"
output: html_document
---
This for final machine learning analysis. 

before running this script first run
01_DataDownload
03_Datawrangling: then go through all the files within chronologically
then you can run this script

1. prep data for RandomForest
2. tune model for RandomForest
3. run Random Forest
4. visualize SHAP values

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

load the packages that you need
```{r}
library(randomForest)
library(missForest)
library(caret)
library(future)
library(here)

pacman::p_load(tidyverse, patchwork, lubridate, akima, reshape2, pracma,
               gridExtra, grid, colorRamps, RColorBrewer, rLakeAnalyzer,
               reader, cowplot, dplyr, tidyr, ggplot2, zoo, purrr, beepr, forecast, ggthemes, splines)

```

This will not run in markdown. Run in your console. 

```{r}
depth_analysis <- read.csv("CSVs/depth_analysis_frame.csv")|>
  filter(year(Date) >2014, year(Date) <2025)
```

Tidy up the frame for depth analysis
```{r}
# Remove non-numeric columns (excluding Date, Depth_m, Year, etc.)
non_numeric_columns <- sapply(depth_analysis, function(x) !is.numeric(x) & !is.factor(x))
final_no_non_numeric <- depth_analysis |>
  select(-which(non_numeric_columns)) 

# Replace Inf and NaN with NA in all numeric columns
final_no_non_numeric <- final_no_non_numeric %>%
  mutate(across(where(is.numeric), ~ ifelse(is.infinite(.) | is.nan(.), NA, .)))

# Remove columns with more than 75% NA values
final_data_no_na <- final_no_non_numeric %>%
  select(where(~ mean(is.na(.)) <= 0.25))  # Keep columns with ≤ 25% NA

# Remove remaining rows with any NA values
RF_depth_analysis <- final_data_no_na %>%
  na.omit()

#write.csv(RF_depth_analysis, here("CSVs", "RF_depth_analysis.csv"), row.names = FALSE)
```


check to see how much is actually going into the analysis
```{r}
check<-depth_analysis |>
    select(where(~ mean(is.na(.)) <= 0.25))  # Keep columns with ≤ 25% NA

RF_frame_w_dates <- check %>%
  na.omit()
 
RF_frame_w_dates %>%
  count(year(Date)) %>%
  print() 
  
```

Grid search. We do not have enough data to split into training and test set. 
```{r}
set.seed(123)

# Initialize empty list to store results
results <- list()

# Counter for indexing
i <- 1

for (tree_num in c(100, 200, 300, 500)) {
  for (node_size in c(2, 4, 6, 8)) {
    for (mt in c(3,4,5,6,7,8,9)) {
      
      model_rf <- randomForest(
        DCM_depth ~ ., 
        data = RF_depth_analysis,
        ntree = tree_num,
        mtry = mt,
        nodesize = node_size,
        importance = TRUE
      )
      
preds <- predict(model_rf, RF_depth_analysis)
obs <- RF_depth_analysis$DCM_depth
rsq_test <- 1 - sum((obs - preds)^2) / sum((obs - mean(obs))^2)
      mse_test <- mean(model_rf$mse)
      
      # Store results
      results[[i]] <- data.frame(
        Trees = tree_num,
        `Node size` = node_size,
        mtry = mt,
        `R-squared` = rsq_test,
        MSE = mse_test
      )
      
      i <- i + 1
    }
  }
}

# Combine into a single data frame
depth_RF_tuning_scores <- do.call(rbind, results)


depth_RF_tuning_scores <- depth_RF_tuning_scores |>
  arrange(desc(`R.squared`))

print(depth_RF_tuning_scores)

#this gives the best score
```  

Now to run the actual model
```{r}

best_params <- depth_RF_tuning_scores[1, ]
test_model_rf <- randomForest(
  DCM_depth ~ .,
  data = RF_depth_analysis,
  ntree = best_params$Trees,
  nodesize = best_params$Node.size, 
  mtry = best_params$mtry,
  importance = TRUE
)
library(randomForest)
#detach("package:ranger", unload=TRUE)  
# Now this will work
importance(test_model_rf)
```

Prep to visualize
```{r}
importance_df <- as.data.frame(importance(test_model_rf))
importance_df <- rownames_to_column(importance_df, var = "Variable") # Convert row names to a column
  
filtered_importance_df <- importance_df %>%
  filter(!is.na(`%IncMSE`), `%IncMSE` > 0)# Filter for valid and positive %IncMSE

rsq_test<- mean((model_rf$rsq))
mse_test<- mean((model_rf$mse))
print(rsq_test)
print(mse_test)
```  

Need to at some point run VIF will come back to this

visualize
```{r save-plot, eval=TRUE}
var_importance_depth_plot <- ggplot(filtered_importance_df, aes(x = `%IncMSE`, y = reorder(Variable, `%IncMSE`))) +
  geom_point(color = "blue", size = 3) +
  labs(
    title = "Variable Importance for Depth Prediction 2015–2024",
    x = "% IncMSE",
    y = "Variables"
  ) +
  scale_x_continuous(expand = expansion(mult = c(0, 0.05)), limits = c(0, NA)) +
  theme(
    panel.background = element_rect(fill = "white", color = NA),
    plot.background = element_rect(fill = "white", color = NA),
    plot.title = element_text(size = 25, hjust = .5),  # Left-align title
    plot.title.position = "plot",  # Positions the title relative to the entire plot area
    axis.title = element_text(size = 18),
    axis.text = element_text(size = 16),
    plot.margin = ggplot2::margin(t = 10, r = 20, b = 10, l = 5) # <- force ggplot2 margin
  )

# Save to a relative directory
ggsave("Figs/var_importance_depth_plot_all_variables.png", plot = var_importance_depth_plot, width = 10, height = 7, dpi = 600)
```

#SHAP
SHAP: SHAP values (SHapley Additive exPlanations) are a way to explain machine learning model predictions by showing how much each feature contributes to a particular prediction.
```{r}
library(fastshap)
library(tidyverse)
library(ggbeeswarm)
library(viridis)
library(forcats)

# Prepare X matrix for shap
X <- data.matrix(select(RF_depth_analysis, -DCM_depth))

# Calculate SHAP values
shap_values <- fastshap::explain(
  test_model_rf, X = X, nsim = 100,
  pred_wrapper = function(x, newdata) predict(x, newdata)
)

# Predicted values and base value
preds <- predict(test_model_rf, X)
base_value <- mean(preds)

cat("shap + base_value:\t", sum(shap_values[1,]) + base_value,
    "\n     prediction:\t", preds[1], "\n")

# Prepare tidy df with feature values and shap values
vars <- as_tibble(X) %>%
  rownames_to_column('row_id') %>%
  pivot_longer(-row_id, names_to = 'var', values_to = 'value')

shaps <- as_tibble(shap_values) %>%
  rownames_to_column('row_id') %>%
  pivot_longer(-row_id, names_to = 'var', values_to = 'shap')

df <- inner_join(vars, shaps, by = c('row_id', 'var'))

# Clean up types
df <- df %>%
  mutate(
    shap = as.numeric(shap),
    value = as.character(value),  # or as.numeric(value) if appropriate
    var = as.character(var)
  )

# Variable ordering for plots
ordered_vars <- filtered_importance_df %>%
  arrange(desc(`%IncMSE`)) %>%
  pull(Variable) %>%
  rev()

# Plot 0: SHAP values for row 1 (the one you liked the most)
plot_shap_1 <- df %>%
  filter(row_id == 1) %>%
  ggplot(aes(x = shap, y = fct_reorder(paste0(var, "=", value), shap), fill = factor(sign(shap)))) +
  geom_col() +
  guides(fill = 'none') +
  labs(y = "", title = "SHAP values for X[1,]") +
  theme_minimal(base_size = 16)

# Plot 1: Distribution of SHAP values with z-scaled coloring
plot_dist <- df %>%
  filter(var %in% ordered_vars) %>%
  mutate(
    value = as.numeric(value),
    var = factor(var, levels = ordered_vars)) %>%
  group_by(var) %>%
mutate(nv = scale(value))%>%
  ungroup()%>%
  ggplot(aes(x = shap, y = var, color = nv)) +
  geom_quasirandom(groupOnX = FALSE, dodge.width = 0.3) +
  scale_color_viridis_c(option = 'H', limits = c(-3, 3), oob = scales::oob_squish) +
  labs(
    title = 'Distribution of SHAP values for Depth Prediction 2015-2024',
    y = '',
    color = 'z-scaled values'
  ) +
theme(
    panel.background = element_rect(fill = "white", color = NA),
    plot.background = element_rect(fill = "white", color = NA),
    plot.title = element_text(size = 25, hjust = .5),  # Left-align title
    plot.title.position = "plot",  # Positions the title relative to the entire plot area
    axis.title = element_text(size = 18),
    axis.text = element_text(size = 16),
    legend.text = element_text(size = 14),     # <-- Increase legend text size
    legend.title = element_text(size = 16),
    plot.margin = ggplot2::margin(t = 10, r = 20, b = 10, l = 5)  # Reduce left margin if needed
  )
# Plot 2: Mean absolute SHAP value
# plot_mean_abs <- df %>%
#   group_by(var) %>%
#   summarize(mean = mean(abs(shap), na.rm = TRUE)) %>%
#   ggplot(aes(x = mean, y = fct_reorder(var, mean))) +
#   geom_col(fill = "steelblue") +
#   labs(
#     x = 'mean(|SHAP value|)',
#     title = 'Mean absolute SHAP for all samples',
#     y = ''
#   ) +
#   theme_minimal(base_size = 16)

# # Plot 3: Mean SHAP by sign
# plot_mean_sign <- df %>%
#   group_by(var, sign = factor(sign(shap))) %>%
#   summarize(mean = mean(shap, na.rm = TRUE)) %>%
#   ggplot(aes(x = mean, y = fct_reorder(var, mean), fill = sign)) +
#   geom_col() +
#   scale_fill_manual(values = c("-1" = "red", "0" = "gray", "1" = "green")) +
#   labs(
#     x = 'mean(SHAP value)',
#     title = 'Mean SHAP for all samples 2014–2023',
#     y = '',
#     fill = 'Sign'
#   ) +
#   theme_minimal(base_size = 16)

# Now you can save plots separately like this:
#dir.create("Figs", showWarnings = FALSE)

#ggsave("shap_values_row1.png", plot_shap_1, width = 8, height = 4, dpi = 600, bg = "white")
ggsave("Figs/ALL VARIABLES_depth_shap_distribution.png", plot_dist, width = 10, height = 8, dpi = 600, bg = "white")
#ggsave("mean_abs_shap.png", plot_mean_abs, width = 10, height = 6, dpi = 600, bg = "white")
#ggsave("mean_shap_by_sign.png", plot_mean_sign, width = 10, height = 6, dpi = 600, bg = "white")

#print(plot_shap_1)
print(plot_dist)
#print(plot_mean_abs)
#print(plot_mean_sign))

```

now to look at specific variables and their values
```{r}
library(ggplot2)
library(dplyr)
library(scales)
library(here)

# Define the list of variables
vars_to_plot <- c('PZ', 'WaterLevel_m', 'thermocline_depth', 'schmidt_stability', 'depth_TFe_mgL_min', 'WindSpeed_Weekly_Average_m_s_lagged')

# Loop and save each plot
for (v in vars_to_plot) {
  
  # Create plot
  p <- df %>%
    filter(var == v) %>%
    mutate(value = as.numeric(value)) %>%
    ggplot(aes(x = value, y = shap)) +
    geom_point() +
    geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
    scale_x_continuous(breaks = pretty_breaks(n = 6)) +
    labs(
      title = paste0('2013–2023 Interaction: SHAP vs ', v),
      x = v,
      y = "SHAP value"
    )
  
  # Print inline for RMarkdown rendering
  print(p)

  # Save to file
  ggsave(
    filename = here::here("Figs/xai_plots", paste0("shap_", v, ".png")),
    plot = p,
    width = 6,
    height = 4,
    dpi = 300
  )
}
```
